---
layout: single
title: '"[DL] CNN의 기본 개념을 알아보자 (1) - CNN의 작동원리 이해하기"'
categories:
  - deep_learning
tags:
  - deep-learning
  - DL
  - 딥러닝
toc: true
highlight: false
use_math : true
header:
  teaser: /assets/images/review_article/deep_learing_thumbnail.jpg
  overlay_image: /assets/images/review_article/deep_learing_thumbnail.jpg
  overlay_filter: 0.5
  caption: "Photo credit: [Unsplash](https://unsplash.com/ko/%EC%82%AC%EC%A7%84/XJXWbfSo2f0)"
---

## 🚦 Summary


---

## 📌 Intro.
- 

---

> 💡 이런걸 정리합니다.


---

### CNN의 작동원리 이해하기 (1) - 필터 사이즈
- [이전 포스팅(Convolution을 이해하고 이미지 처리하기: 딥러닝의 기본 개념과 응용)](https://kimgabe.github.io/personal_study/deep_learning/Convolution_%EC%95%8C%EC%95%84%EB%B3%B4%EA%B8%B0/) 에서 영상분석의 방법을 정리하였습니다.
- 그리고 <font color="#00b050">영상의 특징을 잡아내는 방법은 필터 사이즈를 점점 키워나가는 방법과, 영상의 크기를 점점 줄여나가는 방법 2가지</font>가 있다고 정리하였고, 이 <span style="background:#fff88f">두가지가 복합적으로 적용되는것이 CNN</span>이라고 정리한 바 있습니다.
- 이중 필터 사이즈를 점점 키워나가는 방법 (Convolution Layer를 여러개 쌓기) 가 무엇인지를 이미지 예제와 함께 정리합니다.

![](https://i.imgur.com/5kWqlOr.png)

#### 🤓 [🤔 컨볼루션 연산과정](🤔%20컨볼루션%20연산과정.md) 의 특징
- 결합법칙이 성립합니다.
	- $(f\times g) \times h =f \times (g \times h)$
	- $(f\times g)$ 로 컨볼루션 연산을 하고 $h$와 컨볼루션 연산을 하나 $(g \times h)$ 로 컨볼루션 연산을 하고 나중에 $f$와 컨볼루션 연산을 하나 결과는 같다는 것입니다.
- 이 수식을 CNN의 컨볼루션 연산으로 치환해서 보자면
	- $f$ : (입력)영상 
	- $g$ : <font color="#ff0000">R</font>(ed)/<font color="#00b050">G</font>(reen) 통과시키는 필터
	- $h$ : <font color="#ff0000">R</font>(ed) 통과 필터

---

- 이 특징을 다시 적용하면서 위의 이미지를 풀어 보자면 아래의 두가지는 같은 값을 도출 합니다.
	- $f$라는 영상에 $g$를 컨볼루션 해서 $h$를 컨볼루션하는 것 : $(f\times g) \times h$
	- $g$와 $h$라는 필터를 먼저 컨볼루션한 뒤에 $f$라는 영상과 컨볼루션 하는 것 : $f \times (g \times h)$
- $3 \times 3$  과 $3 \times 3$을 컨볼루션 하면 $5 \times 5$ 형태가 됩니다.
- 이 개념을 적용해서 <font color="#00b050">Convolution Layer를 여러겹으로 쌓음으로써 필터의 크기를 점점 키울 수 있습니다.</font>
---
#### 어떻게 필터가 커지는 것인가?!
- 위 이미지의 1번 표시에는 입력영상($f$) 에 1번째 Convolution Layer인 $g$ 를 적용시킨 것으로 결과는 $3 \times 3$ 일 것입니다.
	- $f$에 $3 \times 3$ 크기의 필터 $g$를 적용한 결과로 $f \times g$ 에 해당합니다.
- 두번째로 $3 \times 3$ 에 $3 \times 3$인 $h$라는 Convolution Layer를 적용시켜 Convolution 연산을 하면 $5 \times 5$ 사이즈의 연산 결과가 나옵니다.
	- $f\times g$의 결과에 $3 \times 3$ 크기의 필터 $h$ 를 적용한 결과는 $f \times (g \times h)$가 됩니다.
	- 결합법칙에 의해 이 두개의 순서에 상관없이 같은 값을 가집니다.
- 세번째로 이 $5 \times 5$ 사이즈의 연산결과에 $3 \times 3$ 사이즈인 세번째 Convolution Layer를 적용시켜 convolution 연산을 하면 그 결과는 $7 \times 7$ 형태가 됩니다.
	- 세번째 필터를 계산하기 전에 $g \times h$ 를 계산하면, $f$에 $5 \times 5$ 크기의 결과를  하는 것과 같습니다.
- 이러한 과정을 거치면서 입력영상($f$) 는 3가지 크기의 필터에 적용을 받아 결과를 도출한 결과가 됩니다.
- 이것이 가능한 이유는 Convolution 연산이 결합법칙이 성립되는 연산이기 때문입니다.

---

### CNN의 작동원리 이해하기 (2) - 영상 사이즈를 점점 작게 만들기

![](https://i.imgur.com/nEdCeEi.png)


- 이를 위해 각 Convolution Layer 사이사이에 영상의 사이즈를 점점 작게 만드는 Max Pooling이라는 [풀링 레이어(Pooling Layer)](풀링%20레이어(Pooling%20Layer).md) 를 삽입해 이미지 크기를 줄입니다.
	- [풀링 레이어(Pooling Layer)](풀링%20레이어(Pooling%20Layer).md) 는 컨볼루션 계층에서 추출된 특징 맵의 크기를 줄이는 역할을 하는 레이어입니다.
	- Max Pooling은 이러한 [풀링 레이어(Pooling Layer)](풀링%20레이어(Pooling%20Layer).md) 의 한 종류로, 맵의 크기를 줄이는 방식입니다.
		- 일종의 하이퍼파라미터 같은 것이라 볼 수 있습니다.
		- 다른 풀링 레이어의 종류로는 Average Pooling 이라는 레이어도 있습니다.
	- Mas Pooling은 특정 영역에서 가장 큰 값을 선택하여 특징 맵의 크기를 줄입니다. 예를 들어, 2x2 영역에서 가장 큰 값을 선택합니다.



---

### CNN의 구조
![](https://i.imgur.com/dDNQyIS.png)

- 위 이미지는 초기의 CNN(합성곱 신경망) 구조 중 하나인 LeNet-5를 보여주고 있습니다. 이 네트워크는 <font color="#00b050">손으로 쓴 숫자를 인식하기 위해 설계</font>되었고, 아래와 같은 여러 층(layer)으로 구성되어 있습니다:

1. <font color="#00b050">입력(Input)</font>: 32x32 크기의 이미지가 네트워크에 입력됩니다. 이 이미지는 숫자를 포함하고 있으며, 네트워크의 목적은 이 숫자를 인식하는 것입니다.
    
2. <font color="#00b050">첫 번째 합성곱 층(C1 - Convolution Layer)</font>: 입력 이미지에 여러 개의 필터(5x5 크기)를 적용해 28x28 크기의 특징 맵(feature map) 6개를 생성합니다.
    
3. <font color="#00b050">첫 번째 맥스풀링 층(S2 - Maxpooling Layer)</font>: 특징 맵의 크기(28 x 28)를 줄이기 위해 2x2 풀링을 적용해 14x14 크기의 특징 맵 6개를 생성합니다.
    
4. <font color="#00b050">두 번째 합성곱 층(C3 - Convolution Layer)</font>: 두 번째 합성곱 층에서는 더 많은 필터를 사용하여 10x10 크기의 특징 맵 16개를 생성합니다.
    
5. <font color="#00b050">두 번째 맥스풀링 층(S4 - Maxpooling Layer)</font>: 다시 풀링을 적용하여 5x5 크기의 특징 맵 16개로 줄입니다.
    
6. <font color="#00b050">완전 연결 층(C5 - Fully Connected Layer)</font>: 이제 합성곱과 풀링으로 추출한 특징들을 사용하여 120개의 노드로 이루어진 완전 연결 층을 거칩니다.
    
7. <font color="#00b050">완전 연결 층(F6 - Fully Connected Layer)</font>: 이전 층의 출력을 받아 84개의 노드로 구성된 또 다른 완전 연결 층을 거칩니다.
    
8. <font color="#00b050">출력(Output)</font>: 마지막으로, 네트워크는 10개의 노드로 구성된 출력 층으로, 각 노드는 하나의 숫자 클래스(0에서 9까지)를 나타냅니다. 소프트맥스 함수나 가우시안 연결(Gaussian connections)을 사용하여 최종적으로 어떤 숫자인지를 결정합니다.
    

> 이 네트워크는 convolution 층과 Max pooling 층을 통해 이미지에서 중요한 특징을 추출하고, 완전 연결 층을 통해 이 특징들을 사용하여 분류 작업을 수행합니다. LeNet-5는 딥러닝에서의 합성곱 신경망의 초기 모델 중 하나로, 현대 CNN의 기초를 제공한 중요한 구조입니다.

---

## Convolution 레이어 구조 살펴보기(1)
![](https://i.imgur.com/7TyNlgP.png)

- 위에 개념을 이해할때는 1개짜리 레이어의 연산과정을 정리했지만, 실제사용되는 Convolution Layer에는 여러개의 Convolution 필터가 있습니다.
- <span style="background:#ff4d4f">한개의 필터 = 한 종류의 feature만 추출이 가능하기 때문입니다.</span>
- 하지만 제대로 이미지/영상의 특징을 추출해서 활용하려면 여러 종류의 feature를 추출하는 것이 학습에 더 도움이 될 것입니다.

![](https://i.imgur.com/2jFfmQq.png)

- $5 \times 5$ 크기의 필터가 16개 있다고 하면 위에 처럼 $16 \times 5 \times 5$ 라고 표기하고 이것을 하나의 [[텐서(Tensor)]]라고 합니다.
- 이 필터를 통과시키고 나면 16종의 feature를 추출할 수 있는 필터입니다.

### 이미지의 채널도 레이어의 개수에 영향을 미친다!
- 일반적으로 이미지의 크기를 `1920 x 1080`이라고 하면 이는 이미지의 크기가 `1920 x 1080`크기의 행렬로 이뤄졌다는 의미입니다.
- 하지만 이 이미지 데이터에는 숨겨진 정보가 있습니다. 바로 이미지의 채널입니다.
	- 컴퓨터에 있는 이미지 파일은 R,G,B라는 3가지 색상 값을 갖고 있습니다.
	- 이 3가지 색상을 이미지의 채널이라고 합니다.
- 간혹 빨강, 초록, 파랑에 1가지를 더해 투명도를 더해 4개의 채널로 저장하는 경우도 있습니다.
	- 혹은 흑백이미지처럼 단일 채널로 저장될 수도 있습니다.
- 정리하자면, <font color="#00b050">일반적으로 이미지의 채널은 3개이고, 하나의 픽셀을 나타내기 위해 3개의 값이 필요합니다.</font>
	- 예를들어 1920 x 1080 크기의 3채널 이미지를 나타내기 위해서는 6220800개(1920 x 1080 x 3)의 값이 필요합니다.
- 실제 CNN의 코드를 구현하고 그 레이어의 개수를 출력해보면 아래와 같습니다.

```python
import tensorflow as tf

# 1장 x 가로 1920 픽셀 x 세로 1080 픽셀 x 3채널(빨, 초, 파)
pic = tf.zeros((1, 1920, 1080, 3))
print("입력 이미지 데이터:", pic.shape)
pic_flatten_out = tf.keras.layers.Flatten()(pic)
print("이미지 데이터 값 개수: ", pic_flatten_out.shape)
print("\n")

single_conv_layer = tf.keras.layers.Conv2D(filters=1, # 1개 필터
                                    kernel_size=(5, 5),    # 5 x 5 크기
                                    use_bias=False)    # bias에 대해서는 여기서는 설명하지 않습니다.
single_conv_out = single_conv_layer(pic)
print("단일 필터 Convolution 레이어:", single_conv_layer.weights[0].shape)
print("단일 필터 Convolution 레이어의 파라미터 수:", single_conv_layer.count_params())
print("단일 필터 Convolution 결과 이미지:", single_conv_out.shape)
single_flatten_out = tf.keras.layers.Flatten()(single_conv_out)
print("단일 필터 Convolution 결과 이미지 데이터 수: ", single_flatten_out.shape)
print("\n")

multiple_conv_layer = tf.keras.layers.Conv2D(filters=16, # 16개 필터
                                    kernel_size=(5, 5),    # 5 x 5 크기
                                    use_bias=False)    # bias에 대해서는 여기서는 설명하지 않습니다.
multiple_conv_out = multiple_conv_layer(pic)
print("16개 필터 Convolution 레이어:", multiple_conv_layer.weights[0].shape)
print("16개 필터 Convolution 레이어의 파라미터 수:", multiple_conv_layer.count_params())
print("16개 필터 Convolution 결과 이미지:", multiple_conv_out.shape)
multiple_flatten_out = tf.keras.layers.Flatten()(multiple_conv_out)
print("16개 필터 Convolution 결과 이미지 데이터 수:", multiple_flatten_out.shape)
```
```
입력 이미지 데이터: (1, 1920, 1080, 3)
이미지 데이터 값 개수:  (1, 6220800)


단일 필터 Convolution 레이어: (5, 5, 3, 1)
단일 필터 Convolution 레이어의 파라미터 수: 75
단일 필터 Convolution 결과 이미지: (1, 1916, 1076, 1)
단일 필터 Convolution 결과 이미지 데이터 수:  (1, 2061616)


16개 필터 Convolution 레이어: (5, 5, 3, 16)
16개 필터 Convolution 레이어의 파라미터 수: 1200
16개 필터 Convolution 결과 이미지: (1, 1916, 1076, 16)
16개 필터 Convolution 결과 이미지 데이터 수: (1, 32985856)
```

- 위 결과에서 주목해야 할 것은 <font color="#00b050">Convolution layer의 weight가 필터의 개수에 따라서도 달라지고, 입력 이미지의 채널에 따라서도 달라진다는 점</font>입니다. 특히 <font color="#00b050">입력 이미지의 채널에 따라 달라지기도</font> 합니다.
- 채널이 2개라고 가정하면 아래 이미지처럼 Convolution 필터도 2채널이 필요합니다. 
  ![](https://i.imgur.com/PLefPAp.png)

✔️ <font color="#c0504d">필터가 2개인 것</font>과 <font color="#00b0f0">필터의 채널이 2인 것</font>이 <font color="#00b050">다르니 혼동될 수 있으니 유의해야 합니다.</font>



## 🎈 Outro.
- 
