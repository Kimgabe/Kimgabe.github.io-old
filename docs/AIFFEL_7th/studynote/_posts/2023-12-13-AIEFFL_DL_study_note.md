---
layout: single
title: 9. (밑시딥) 학습관련 기술들 (Chapter 6)
categories:
  - studynote
toc: true
highlight: false
header:
  teaser: /assets/images/retrospective.jpg
  overlay_image: /assets/images/retrospective.jpg
  overlay_filter: 0.5
  caption: "Photo credit: [**Unsplash**](https://unsplash.com/photos/52jRtc2S_VE)"
tags:
  - 밑바닥부터배우는딥러닝
  - 학습관련기술들
  - Chapter06
  - 최적화
---
## [매개변수(Parameters)](매개변수(Parameters).md) 갱신
- [신경망(Neural Network)](신경망(Neural%20Network).md) 학습의 목적은 [손실 함수 (Loss Function)](손실%20함수%20(Loss%20Function).md) 값을 가능한 낮추는 [매개변수(Parameters)](매개변수(Parameters).md) 를 찾는 것입니다.
- 즉, 매개변수의 최적값을 찾는 것이 목표이며, 이러한 과정을 [최적화(Optimization)](최적화(Optimization).md) 라 합니다.
- 다만 이런 최적화는 매우 어려운 문제입니다. 매개변수의 공간이 매우 넓고 복잡하기 때문에 말그대로 '최적'의 값을 찾는건은 매우 지난하고 어려운 작업입니다.
- 단순 퍼셉트론에서도 어려운 일이다보니 심층 신경망으로 그 대상이 바뀐다면 더더욱 작업은 어려워 집니다.

### [[SGD(Stochastic Gradient Descent, 확률적 경사하강법)]]
- 확률적 경사하강법의 수식을 표현하면 다음과 같습니다.
  $$W \leftarrow W - \eta \frac{\partial L}{\partial W}$$
	- $\eta$ 는 학습률(learning rate) 을 의미
	- $\leftarrow$ 는 우변의 값으로 좌변의 값을 갱신한다는 의미
- 이를 파이썬 코드로 표현하면 아래와 같습니다.

```python
# SGD(Stochastic Gradient Descent) 클래스 정의
class SGD:
    # 생성자 메서드 (인스턴스 초기화)
    def __init__(self, lr=0.01):
        # 학습률(learning rate)을 설정합니다. 기본값은 0.01로 설정
        self.lr = lr

    # 가중치 및 그래디언트 업데이트 메서드
    def update(self, params, grads):
        # params: 가중치 및 편향 파라미터들을 담고 있는 딕셔너리
        # grads: 가중치 및 편향 파라미터에 대한 그래디언트들을 담고 있는 딕셔너리

        # params 딕셔너리의 키(파라미터 이름)를 하나씩 반복
        for key in params.keys():
            # 현재 파라미터 값을 학습률(self.lr)과 해당 파라미터의 그래디언트(grads[key])를 곱한 값만큼 업데이트
            params[key] -= self.lr * grads[key]
```

- params와 grads 는 딕셔너리 변수
	- `params['W1']` , `grads['W1']` 와 같이 각각 가중치에 매개변수와 기울기를 저장
- 💡 실제 코드로 작동을 시킬때는 이 SGD를 optimizer에 선언하여 적용시킬 최적화 방법론을 변경시킬 수 있습니다.

#### SGD의 단점
- SGD의 장점은 단순하고, 구현이 쉽지만 문제에 따라서 비효율적일 때가 있다는 것 입니다.
- 이를 살펴보기 위해 SGD가 잘작동하는 경우와 그렇지 않은 경우를 각각 시각화 하여 살펴보겠습니다. 
##### SGD가 잘 작동하는 함수의 경우

![](https://i.imgur.com/y3oO1WJ.png)

- 그래프에 대한 설명에 앞서 통상적으로 각 그래프가 가진 정보가 어떤 것인지 정리해보았습니다.

1. **함수의 3D 그래프**
- 목적 : 함수를 3차원으로 표현함으로서 함수의 형태와 경사도를 시각적으로 이해하기 위해 사용됩니다.
- 정보 : 이 그래프를 통해 함수의 전체적인 형태, 최소값 지점, 고원(plateau), 봉우리(ridge), 계곡(vally) 등의 특징을 한눈에 파악할 수 있습니다.
	- 최소값 지점(Minimum Point)
		- 함수의 값이 가장 낮은 지점
		- 최적화 과정의 목표지점
		- 신경망 학습의 최적 매개변수를 찾을 수 있는 지점
	- 고원(Plateau)
		- 함수가 거의 변하지 않는 평범한 지역
		- 최적화 과정에서 고원 지역을 만나면, 경사하강법이 느려지거나 정체될 수 있음
		- 학습률 조정이나 모멘텀 같은 방법을 통해 극복 가능
	- 봉우리(Ridge)
		- 함수의 값이 주변보다 높은 지역
		- 경사하강법은 이 봉우리르 피해 최소값을 찾아야 함
		- 신경망 학습에서는 봉우리를 넘어서야만 더 낮은 손실의 영역에 도달할 수 있음
	- 계곡(Valley)
		- 봉우리에 대응되는 개념, 함수의 값이 주변보다 낮은 지역
		- 계곡을만나면 종종 최소값으로 이어지는 경로가 될 수 있음
		- 그러나 계곡이 매우 길고 좁다면, 경사하강법이 계곡을 따라 매우 천천히 이동할 수도 있음
		  
2. **등고선 그래프(Countour Plot)**
- 목적 : 3D 그래프를 2D로 표현해서 함수의 높이를 등고선으로 표현한 것. 최적화 과정을 시각화 하는데 매우 유용
- 정보
	*- 등고선의 간격*
		- 간격이 좁을수록 기울기가 크고, 손실 함수의 변화율이 크며, 3D 그래프에서의 경사가 가파르다는 것을 의미합니다.
			- 간격이 좁다 = 기울기가 크다 = 손실함수 변화율이 크다 = 3D 그래프의 경사가 가파르다.
		- 간격이 넓을수록 기울기가 작고, 손실 함수의 변화율이 작으며, 3D 그래프에서의 경사가 완만하다는 것을 의미합니다.
			- 간격이 넓다 = 기울기가 작다 = 손실함수 변화율이 작다 = 3D 그래프의 경사가 완만하다.
		- 즉, 등고선이 밀집해 있는 지점은 함수의 값이 급격하게 변하는 곳으로, 이 지점에서는 손실함수의 높이(값)가 빠르게 증가하거나 감소하는 지점임을 의미합니다.
	*- 등고선의 최적화 경로*
		- SGD로 최적화하는 경로를 등고선에 그린다면, 이 경로는 기울기가 작은 부분(등고선의 간격이 넓은 부분)에서 기울기가 큰 부분(등고선의 간격이 조밀한 부분)으로 이동하게 됩니다.
		- 이는 함수의 값(기울기)을 감소시키는 방향이며, 최소값을 향한 경로를 나타냅니다.
		- 즉, 등고선이 밀집해 있는 방향은 기울기가 가장 큰 상승 방향을 가리키지만, 경사하강법은 이 반대 방향으로 이동하며 최소값을 찾아갑니다.
		  
3. **기울기의 벡터 필드(Gradient Vector Filed)**
- 목적 : 기울기를 시각화한 그래프는 각 지점에서 함수의 기울기 방향과 크기를 화살표로 표현
- 정보
	- 함수의 각 지점에서의 경사 방향을 알 수 있음
	- 이를 바탕으로 경사하강법으로 파라미터를 어떤 방향으로 업데이트 해야 할지를 시각적으로 파악할 수 있음
	- 화살표의 길이는 기울기의 크기(손실 함수의 변화율)를 나타내며, 이는 최적화과정에서 업데이트의 방향(파라미터값의 양수/음수)과 크기(업데이트할 파라미터값)를  정하는데 활용 됩니다.
		- 화살표의방향 : 기울기 벡터가 가리키는 다차원 공간에서의 방향
		- 화살표의 크기(=벡터 값) : 기울기 벡터가 가진 값으로 화살표 방향대로 얼마나 이동할지에 대한 스칼라값

---

- 이제 다시 SGD가 잘 작동하는 경우의 그래프를 살펴보겠습니다.
![](https://i.imgur.com/y3oO1WJ.png)

- 위 그래프들은 확률적 경사 하강법(Stochastic Gradient Descent, SGD)의 작동 원리를 시각화하기 위한 것입니다. 
- 여기서 사용된 함수는 $f(x,y) = x^2 + y^2$ 이며, 그 기울기는 $\nabla f(x,y) = [2, 2y]$ 입니다. 
- 각각의 그래프에 대한 해석은 다음과 같습니다.

1. **3D 그래프**
    - 이 그래프는 $f(x,y)$ 함수의 3차원 형태를 보여줍니다.
    - $x$와 $y$ 축은 입력 변수를 나타내고, $z$ 축은 함수의 결과값을 나타냅니다.
    - 함수의 형태는 포물선 모양의 그릇과 같은 형태로, 최소점이 중앙에 위치합니다.
      
2. **등고선 + 기울기 벡터 필드 그래프**:
    - 이 그래프는 함수의 등고선(Contour)과 기울기 벡터 필드를 나타냅니다.
    - 등고선은 함수의 높이를 2D 평면에 나타내며, 밀집할수록 경사가 가파릅니다.
    - 기울기 벡터는 각 지점에서의 가장 빠른 상승 방향을 보여줍니다. 
        - 여기서는 3D그래프와의 이해를 돕기 위해 기울기값에 음수를 취해 벡터의 반대 방향으로 표시했습니다.
    - 빨간 점과 선은 SGD 경로를 나타내며, 이는 최소값을 찾아가는 경로를 보여줍니다.
      
3. **기울기 벡터 필드만 표시하는 그래프**:
    - 이 그래프는 기울기 벡터 필드만을 보여줍니다.
    - 각 화살표는 해당 지점에서 기울기가 가장 많이 증가하는 방향을 나타냅니다.
        - 여기서는 3D그래프와의 이해를 돕기 위해 기울기값에 음수를 취해 벡터의 반대 방향으로 표시했습니다.
    - 이 그래프는 경사 하강법이 어떻게 작동하는지를 직관적으로 이해하는 데 도움을 줍니다.

- 코드는 이 세 그래프를 통해 SGD가 어떻게 최적화 문제를 해결하는지 시각적으로 보여줍니다. 
- 시작점(9,9)에서 시작하여, 각 단계마다 기울기에 비례하여 위치를 조정함으로써 최소값을 향해 점점 이동하는 과정을 볼 수 있습니다. 
- 이는 머신 러닝에서 비용 함수를 최소화하는 과정을 예시로 보여주는 좋은 방법입니다.


📌 참고로 실제 손실 함수의 기울기를 표현한 화살표는 각 지점에서 함수값이 가장 빠르게 증가하는 방향을 가리키고, 이는 원점(0,0)에서 멀어지는 방향입니다. 하지만, (확률적) 경사하강법에서는 이 기울기의 반대 방향으로 이동해서 함수의 최소값을 찾습니다.(=매개변수를 업데이트합니다.) 
왜냐하면, 기울기가 증가(손실함수의 값이 증가)하는 방향으로 이동할 경우, 이는 함수의 값을 증가시키는 것이기 때문입니다. 


---

- 다시 본문으로 돌아와 SGD의 단점을 단적으로 드러나는 예시를 살펴보겠습니다.

##### SGD가 잘 작동하지 않는 함수의 경우(feat. 비등방성 함수)

$$f(x,y) = \frac{1}{20}x^2+y^2$$ 
- 위 함수의 최소값을 구하기 위한 손실 함수를 시각화 하면 아래의 그래프와 같습니다.

![](https://i.imgur.com/Ai7QsOu.png)


- 3D 그래프도 x축 방향으로 늘어진 모양이고, 등고선도 x축 방향으로 늘인 타원형태로 구성되어 있습니다.
- 함수의 기울기를 그린 벡터 필드 그래프를 봐도 기울기의 대부분이 (0,0)을 가리키지 않고 있습니다.
- 이 함수를 SGD를 사용해서 최적화 경로를 그린 두번재 그래프를 더 확대해 보겠습니다.

![](https://i.imgur.com/swUPpdG.png)

- (0,0) 을 향해 일정한 방향성으로 나아가지 못하고 지그재그로 불필요한 움직임을 가지면서 비효율적으로 최적값을 찾아가고 있는 것을 확인할 수 있습니다.
	- 😑 SGD가 최적화 방향을 잘 찾지 못하는 모습을 극적으로 연출하기 위해 학습률을 다소 높여 그리긴 했습니다.
	- 실제로 그냥 함수대로 그래프 그리면 (0,0) 에 학습 한번으로 도달하지 못할뿐 균일한 방향으로 움직이기는 합니다.
- 이렇게 불필요한 움직임을 가지는 이유는 SGD가 예시로 제시한 $f(x,y) = \frac{1}{20}x^2+y^2$ 와 같은  [[비등방성 함수(Anisotropic function)]] 에서는 비효율적인 움직임을 보인다는 것 입니다.
	- 비등방성 함수는 모든 방향에 대해 함수의 특성이 동일하지 않은 함수(위 이미지 참고)로 특정 방향으로는 함수의 변화율(기울기)가 크고 다른 방향으로는 변화율이 작다는 특성이 있습니다.
	- SGD는 각 단계에서 현재 위치의 기울기가 급격하게 변하는 방향으로 이동하려 합니다.
	- 하지만 이러한 SGD의 특성이 비등방성 함수와 만나면 [지역 최소값(Local Minimum)](지역%20최소값(Local%20Minimum).md)  으로 향하는 방향과 반드시 일치하지는 않는 상황이 발생합니다.

- 즉, 경우에 따라서는 무조건 기울어진 방향으로만 탐색을 하는 방법이 아닌 다른 방법이 필요합니다.
- 이러한 방법으로는 [[모멘텀(Momentum)]], [[AdaGrad]], [[Adam]] 등이 있습니다. 

### [모멘텀(Momentum)](모멘텀(Momentum).md) 
- Momentum 은 단어 뜻 그대로 '운동량' 또는 '관성' 을 뜻하는 것으로 최적화를 함에 있어 '물리' 와 관계가 있습니다.
	- 📌 Momentum SGD 라고도 함
- 모멘텀의 수식은 아래와 같습니다.
  $$v \leftarrow av - \mu \frac{\partial L}{\partial W}$$
- 여기서 $v$ 는 물리에서 말하는 속도($velocity$) 를 의미합니다.
- $a$ 는 관성계수를 의미하며, $av$ 는 관성계수에 속도를 곱한 값으로 물체가 아무런 힘을 받지 않았을 때도 서서히 하강하도록 합니다.
	- 관성계수 : 물체가 운동상태를 유지하려는 정도를 말합니다.
- 모멘텀은 이러한 물리적 개념을 차용해 기울기가 변하는 방향에 가속도($v$) 를 부여함으로서 [지역 최소값(Local Minimum)](지역%20최소값(Local%20Minimum).md) 더 바르게 찾는 것을 목표로 합니다.
- 모멘텀의 기본 컨셉은 이전 스텝에서 계산된 기울기에 관성을 부여해 현재 단계의 업데이트에 반영하는 것입니다.
![](https://i.imgur.com/JLWsaAJ.png)

- 모멘텀이 작동하여 움직이는 과정을 gif로 표현하면 아래와 같습니다.

![](https://i.imgur.com/R8qOlJL.gif)

#### 모멘텀의 수식구현
```python
class Momentum:
    """모멘텀 SGD (Stochastic Gradient Descent) 클래스"""

    def __init__(self, lr=0.01, momentum=0.9):
        # 학습률(learning rate)과 모멘텀(momentum)을 초기화합니다.
        self.lr = lr  # 학습률은 기본값으로 0.01을 사용합니다.
        self.momentum = momentum  # 모멘텀은 기본값으로 0.9를 사용합니다.
        self.v = None  # 속도(v) 변수를 초기화합니다.

    def update(self, params, grads):
        # 만약 초기에 속도(v)가 None이라면, 각 매개변수에 대한 속도(v)를 0으로 초기화합니다.
        if self.v is None:
            self.v = {}
            for key, val in params.items():
                self.v[key] = np.zeros_like(val)

        # 매개변수(params)와 그래디언트(grads)를 이용하여 업데이트를 수행합니다.
        for key in params.keys():
            # 모멘텀 SGD의 업데이트 공식을 적용합니다.
            self.v[key] = self.momentum * self.v[key] - self.lr * grads[key]
            params[key] += self.v[key]

```
- 이 코드는 모멘텀 SGD(Stochastic Gradient Descent)를 구현한 클래스입니다. 모멘텀 SGD는 기존의 SGD에 모멘텀 개념을 추가하여 학습 과정을 안정화시키는 데 도움을 줍니다. 이 코드의 작동 과정을 설명해드리겠습니다.

1. **클래스 초기화**
    - `__init__` 메서드에서 클래스 인스턴스를 초기화합니다.
    - `lr`은 학습률(learning rate)로, 기본값은 0.01입니다. 학습률은 매개변수 업데이트 시 얼마나 크게 조정할지를 결정합니다.
    - `momentum`은 모멘텀(momentum) 상수로, 기본값은 0.9입니다. 모멘텀은 이전 그래디언트의 방향을 얼마나 고려할지를 결정하는 요소입니다.
    - `v`는 초기에는 None으로 설정되며, 업데이트할 때 사용될 속도 벡터입니다.
      
2. **업데이트 메서드**
    - `update` 메서드는 모델의 매개변수(params)와 그래디언트(grads)를 받아와서 모멘텀 SGD 업데이트를 수행합니다.
    - 초기에는 속도(v)가 None이면, 각 매개변수와 같은 형태의 영벡터로 초기화합니다.
    - 각 매개변수에 대해 다음과 같은 과정을 수행합니다:
        - 현재 속도(v)에 이전 속도(v)에 모멘텀(momentum)을 곱하고 그래디언트에 학습률(lr)을 곱한 값을 빼줍니다. 이렇게 계산된 값은 새로운 속도(v)가 됩니다.
        - 매개변수(params)는 이 새로운 속도(v)를 더함으로써 업데이트됩니다.

> 이러한 과정을 통해 모멘텀 SGD는 그래디언트의 방향과 속도를 고려하여 매개변수를 업데이트하고, 이전 그래디언트의 영향을 계속 반영하여 안정적으로 학습을 진행합니다.


#### 모멘텀의 최적화 수행과정
- 이 모멘텀을 사용해서 비등방성 함수의 수식에 대한 최적화 경로를 그려보겠습니다.
$$f(x,y) = \frac{1}{20}x^2+y^2$$ 
![](https://i.imgur.com/XMwo1nQ.png)

- 위의 예시 이미지에서 본 것 처럼 모멘텀의 갱신 경로는 공이 경사면을 구르듯 움직입니다.
- SGD보다 지그재그로 움직이는 정도가 훨씬 덜한 것을 확인할 수 있습니다.
- 이는 $x$ 축의 힘(기울기)은 아주 작지만 그 방향의 변화가 적고, 일정한 방향으로 가속(관성이 작용) 하기 때문입니다.
- 다만 $y$ 축의 힘(기울기)은 커서 위아래로 번갈아 힘을 받아 $y$ 축 방향의 속도(파라미터의 업데이트 크기)는 안정적이지 않습니다.

#### 모멘텀은 [안장점(Saddle Point)](안장점(Saddle%20Point).md) 의 한계를 극복할 수 있다
- 4장에서 안장점에 대해 정리한 적이 있습니다. 이때, 경사하강법이 안장점에 도달하면 학습이 진행되지 않고 정체되는 현상이 발생할 수 있음을 배웠습니다.
- 다시한번 안장점에 대해 정리하면 아래와 같습니다.

![안장점(Saddle Point)](안장점(Saddle%20Point).md)

- [모멘텀(Momentum)](모멘텀(Momentum).md) 은 이러한 경사하강법이나 SGD가 가진 안장점에서의 한계를 극복할 수 있습니다.
- 아래 이미지를 보면 좌측의 공처럼 [지역 최소값(Local Minimum)](지역%20최소값(Local%20Minimum).md) 에 도달했음에도 불구하고 지속적으로 움직여 더 낮은 최적값으로 이동함을 알 수 있습니다.

![](https://i.imgur.com/ekSJ797.png)

- 이것이 가능한 이유는 모멘텀이 이전 움직임에서 발생한 관성을 유지하면서 최적경로를 향하기 때문입니다.
- 이를 모멘텀의 연산식과 함께 정리해보면 아래와 같습니다.

1. **모멘텀 수식 정의**
    - $v_t = \gamma v_{t-1} + \eta \nabla f(x_{t-1})$
    - $x_t = x_{t-1} - v_t$
        - 여기서 $\gamma$는 관성계수이며, $v_t$는 $t$ 번째 스텝에서의 $x$의 이동 벡터입니다.
          
2. **$x_t$의 의미**
    - $x_t$는 0번째 이동(시작점)에서의 $x$ 값에서 $v_t$를 빼준 값입니다.
      
3. **$v_t$의 의미**
    - $v_t$는 0번째 스텝에서 1번째 스텝으로의 이동 벡터값을 의미합니다.
      
4. **이동 벡터값 $-v_t$의 해석**
    - $\eta \nabla f(x_{t-1})$ 부분은 학습률($\eta$)과 그래디언트의 곱입니다.
    - $-v_t$에서 마이너스를 제거하면 $-\nabla f(x_{t-1})$가 되며, 이는 일반적인 그래디언트 계산 수식입니다.
      
5. **모멘텀과 그래디언트의 차이점**
    - 모멘텀과 그래디언트의 차이는 $\gamma v_{t-1}$ 부분입니다.
    - $\gamma v_{t-1}$는 이전 속도 $v_{t-1}$에 관성계수 $\gamma$를 곱한 값입니다.
      
6. **모멘텀 수식의 총체적 해석**
    - 이 수식은 바로 직전 스텝의 속도를 기억하고, 그 속도에 관성계수를 곱해 다음 스텝에 영향을 주는 방식입니다.
    - 이는 관성의 힘을 이동 방향에 더해준 결과입니다.

> ➕ 이러한 원리 때문에 모멘텀을 적용하면 Local Minimum(그래프의 좌측 부분) 과 잡음(그래프의 우측 부분)에 대응할 수 습니다.
> ➖ 반면에 이동 벡터($v_t$) 를 추가로 사용해, SGD 대비 2배의 메모리를 더 사용한다는 단점이 있습니다.


---

### AdaGrad (적응적 기울기, Adaptive Gradient)
- 앞서 경사하강법에 대해 정리할 때, 학습률(Learning Rate) 의 중요성에 대해 배운적이 있습니다.
	- 학습률의 값이 너무 작으면 학습 시간이 너무 길어지고, 너무 크면 발산하여 학습이 제대로 이뤄지지 않습니다.
- 이러한 학습률을 정하는 효과적인 기술중 하나가 [[학습률 감소(Learning rate decay)]] 입니다.
	- 쉽게 말해, 학습을 진행하면서 학습률을 점차 줄여나가는 전략을 말합니다.
- 이러한 학습률 감소는 대부분의 최적화 알고리즘에서 사용하지만, '학습률을 서서히 낮춘다' 는 전략을 실행하는 방법중 가장 간단한 것은 '전체 학습률값' 을 일괄적으로 낮추는 것입니다.
- 이러한 방법을 발전시킨것이 AdaGrad 입니다. AdaGrad의 수식은 아래와 같습니다.

- 1. $h \leftarrow h+ \frac{\partial L}{\partial W} \odot \frac{\partial L}{\partial W}$
    - 이 부분은 $h$를 업데이트하는 규칙입니다. 
    - $h$는 각 파라미터에 대한 그래디언트의 제곱합을 저장합니다. 
    - $\frac{\partial L}{\partial W}$는 손실 함수 $L$에 대한 가중치 $W$의 그래디언트를 나타내며, $\odot$는 요소별 곱셈을 나타냅니다. 
    - 즉, 이 규칙은 현재 그래디언트의 제곱을 $h$에 더하는 것입니다.
      
2. $W \leftarrow W- \eta \frac {1}{\sqrt h} \cdot \frac{\partial L}{\partial W}$
    - 이 부분은 가중치 $W$를 업데이트하는 규칙입니다. $\eta$는 학습률을 의미합니다. 
    - 이 규칙은 가중치를 그래디언트의 방향으로 학습률 만큼 이동시킵니다. 이때 그래디언트는 $\frac {1}{\sqrt h}$로 조정됩니다. 
    - 이렇게 하면 $h$가 큰 파라미터(즉, 이전에 크게 변화한 파라미터)의 학습률은 작아지고, $h$가 작은 파라미터(즉, 이전에 작게 변화한 파라미터)의 학습률은 커집니다.

> 즉, AdaGrad는 각 파라미터에 대해 학습률을 개별적으로 조정하여, 빈번하게 업데이트되는 파라미터의 학습률을 감소시키고, 드물게 업데이트되는 파라미터의 학습률을 증가시킵니다. 
> 이로 인해 AdaGrad는 비등방성 함수에서 효과적으로 최적화를 수행할 수 있습니다.

#### AdaGrad 수식 구현
```python
class AdaGrad:

    """AdaGrad"""

    def __init__(self, lr=0.01):
        # 초기화 함수입니다. AdaGrad 클래스를 생성할 때 learning rate를 설정할 수 있습니다.
        self.lr = lr
        
        # h 변수는 각 매개변수의 과거 제곱 그래디언트 값을 저장하는 사전입니다.
        self.h = None
        
    def update(self, params, grads):
        # update 함수는 매개변수(params)와 그래디언트(grads)를 받아와서 AdaGrad 업데이트를 수행합니다.
        if self.h is None:
            # h가 None인 경우, 초기화를 수행합니다.
            self.h = {}
            for key, val in params.items():
                # 각 매개변수의 크기와 동일한 모양을 가진 0으로 채워진 배열을 생성합니다.
                self.h[key] = np.zeros_like(val)
            
        for key in params.keys():
            # 각 매개변수에 대해서 AdaGrad 업데이트를 수행합니다.
            
            # 현재 매개변수의 그래디언트 값을 제곱하여 h에 더해줍니다.
            self.h[key] += grads[key] * grads[key]
            
            # 매개변수를 업데이트합니다. 이때, learning rate로 나누고, h에 작은 상수(1e-7)를 더해줍니다.
            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)

```

- 이 코드는 AdaGrad라는 최적화 알고리즘의 동작 과정을 구현한 것입니다. 
- 이 알고리즘은 머신 러닝 및 딥 러닝에서 매개변수(가중치)를 업데이트하는 데 사용됩니다. 

1. **클래스 초기화(`__init__` 함수)**
    - AdaGrad 클래스를 초기화할 때, learning rate (lr)를 인수로 받을 수 있습니다.
    - lr은 학습 속도를 조절하는 하이퍼파라미터로, 기본값은 0.01입니다.
    - `self.lr`에 lr을 저장하고, `self.h`를 None으로 초기화합니다. `self.h`는 매개변수의 과거 제곱 그래디언트 값을 저장하기 위한 사전입니다.
      
2. **업데이트 함수(`update` 함수)**
    - `update` 함수는 최적화된 매개변수를 얻기 위한 핵심 메서드입니다.
    - 이 함수는 두 개의 인수, `params`와 `grads`,를 받습니다.
    - `params`는 최적화할 매개변수가 담긴 사전이며, `grads`는 해당 매개변수들의 그래디언트가 담긴 사전입니다.
      
3. **초기화(`if self.h is None:`)**
    - `self.h`가 None인 경우, 매개변수마다 그래디언트의 제곱을 저장하기 위한 `self.h` 사전을 초기화합니다.
    - 매개변수 사전 `params`의 각 키(key)에 해당하는 매개변수의 크기와 동일한 모양을 가진 0으로 채워진 배열을 `self.h`에 저장합니다.
      
4. **AdaGrad 업데이트**
    - 각 매개변수에 대해 AdaGrad 업데이트를 수행합니다.
    - 매개변수 사전 `params`의 각 키(key)에 대해서 아래 과정을 반복합니다.
        - 현재 매개변수의 그래디언트 값을 제곱하여 `self.h`에 더합니다. 이렇게 하면 그래디언트의 제곱이 누적됩니다.
        - 매개변수를 업데이트합니다. 이때, learning rate `self.lr`로 나누고, `self.h`의 해당 매개변수 항목에 작은 상수(1e-7)를 더합니다. 이렇게 함으로써 매개변수의 업데이트가 스케일링되며, 학습 속도를 조절할 수 있습니다.

💡 마지막줄에 `1e-7` 을 더하는 이유
```python
params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)
```
- 이는 AdaGrad 에서 분모가 0이 되는것을 방지하기 위해서 입니다.
- 그래디언트의 제곱을 누적하다보면 분모가 0이되어 연산이 불가능해지는 문제가 발생합니다.
- 이를 방지하기 위해 아주 작은 양수값을 더해준 것입니다. (0이 되지 않도록 하기 위해)

- 이제 모멘텀처럼 AdaGrad을 사용해서 비등방성 함수의 수식에 대한 최적화 경로를 그려보겠습니다.
#### AdaGrad의 최적화 수행과정
$$f(x,y) = \frac{1}{20}x^2+y^2$$ 
![](https://i.imgur.com/pdLPz0W.png)


- SGA와 달리 효율적으로 최소값을 향해 최적화가 진행되는 것을 확인할 수 있습니다.
- $y$ 축 방향은 기울기가 커서 처음에는 크게 움직이지만, 그 큰움직임에 비례해 갱신정도 또한 큰 폭으로 작아지도록 조정됩니다.
- 따라서 위 그래프에서 점의 간격이 점차 좁아지는 것을 확인할 수 있습니다.

#### 수식으로 보는 AdaGrad의 단점
- AdaGrad를 수식으로 표현하면 아래와 같습니다.
  
$g_t = g_{t-1} + (\nabla f(x_{t-1}))^2$
$x_t = x_{t-1} - \frac {\eta}{\sqrt g_t + \epsilon} \cdot \nabla f(x_{t-1})$

1. $g_t = g_{t-1} + (\nabla f(x_{t-1}))^2$
    - 이 부분은 $g_t$를 업데이트하는 규칙입니다. 
    - 여기서 $g_t$는 시간스텝 $t$에서 각 파라미터에 대한 그래디언트의 제곱합을 저장합니다. 
    - $\nabla f(x_{t-1})$는 함수 $f$에 대한 $x_{t-1}$의 그래디언트를 나타냅니다. 
    - 이 수식은 현재 그래디언트의 제곱을 이전 시간스텝의 $g_{t-1}$에 더하는 것입니다. 
    - 이렇게 함으로써, 각 파라미터가 이전에 얼마나 많이 변화했는지의 정보를 $g_t$에 저장할 수 있습니다.
      
2. $x_t = x_{t-1} - \frac {\eta}{\sqrt g_t + \epsilon} \cdot \nabla f(x_{t-1})$
    - 이 부분은 파라미터 $x_t$를 업데이트하는 규칙입니다. 
    - 여기서 $\eta$는 학습률을 의미하고, $\epsilon$은 0으로 나누는 것을 방지하는 아주 작은 상수입니다(일반적으로 1e-8). 
    - 이 수식은 파라미터를 그래디언트의 방향으로 학습률 만큼 이동시킵니다. 
    - 이때 그래디언트는 $\frac {1}{\sqrt g_t + \epsilon}$로 나눠줌으로써 학습이 많이된 원소일수록 학습률이 낮아지도록 조정됩니다. 
        - $\sqrt g_t$  로 루트를 씌우는 이유는 $g_t$ 계산에 제곱이 들어가 있기 때문에 원래 미분값을 되찾도록 하기 위함이고, $\epsilon$ 을 더해준 것은 $g_t$ 가 0에 가까우면 `inf` 가 될 수 있기 때문에 이를 방지하기 위한 값 입니다.
    - 이렇게 함으로써, 이전에 크게 변화한 파라미터(즉, $g_t$가 큰 파라미터)의 학습률은 작아지고, 이전에 작게 변화한 파라미터(즉, $g_t$가 작은 파라미터)의 학습률은 커집니다.

✔️ element-wise 
- 벡터, 행렬, 또는 다차원 배열 등의 데이터 구조에서 각 요소에 독립적으로 연산을 적용하는 것을 의미합니다.

🤔 왜 $g_t$ 에서 element-wise `제곱`을 사용하는걸까?
- Element-wise 제곱을 하는 이유는 각 변수에 대한 기울기의 변화를 제곱하여 누적하는 것은 큰 기울기 값을 더 중요하게 다루기 위함입니다. 
- 제곱을 하면 큰 기울기는 더욱 커지고 작은 기울기는 상대적으로 덜 중요하게 됩니다. 
- 이렇게 함으로써, 자주 변화하는 변수는 더 빨리 학습률이 감소하게 만듭니다.

🤔 그렇다면 $x_t$ 에서 element-wise `곱`을 하는 이유는?
- Element-wise 곱은 각각의 원소에 독립적으로 연산을 적용하는 것을 의미합니다.
- AdaGrad는 각 변수의 중요도에 따라 개별적으로 학습률을 조정하기 때문에 

> ➕ 기울기가 커서 학습이 많이 된 변수의 학습률을 낮춰 다른 변수들이 더 잘 학습되게 한다.
> ➖ $g_t$ 가 계속해서 커져서 학습이 오래 진행되면 더이상 학습이 이뤄지지 않는 단점이 있다.

### AdaGrad의 단점을 보완하는 [[RMSProp]]
- 이러한 AdaGrad의 단점을 보완하기 위해 고안된 것이 RMSProp입니다.
- 수식으로 표현하면 아래와 같습니다.

$g_t = \gamma g_{t-1} + (1- \gamma)(\nabla f(x_{t-1}))^2$ 
$x_t = x_{t-1} - \frac {\eta}{\sqrt g_t + \epsilon} \cdot \nabla f(x_{t-1})$ 👉 아래쪽 수식은 동일

- AdaGrad의 수식과 달라진 점은 $g_t$ 의 수식에서 $\gamma$ 를 $gt_{t-1}$ 에 곱해주고 $(\nabla f(x_{t-1}))^2$ 의 앞에 $(1- \gamma)$ 를 곱해준 것 뿐입니다.
- 즉, $g_t$ 의 값을 지속적으로 더해주는 기존의 방식과 달리 지수평균으로 바꿔준 것입니다.
	- 이전값인 $g_{t-1}$ 에 $\gamma$ 를 곱해주고 새로운 값인 $(\nabla f(x_{t-1}))^2$ 에 $(1- \gamma)$ 를 곱해 줘서 AdaGrad 때와는 달리 $(\nabla f(x_{t-1}))^2$ 라는 그래디언트의 값을 $g_t$ 가 천천히 따라가는 모양새가 됩니다.
	- 여기서 $\gamma$ 는 decay rate(감쇠율) 을 의미합니다.
	- 결론적으로 수식이 표현하는 것은 AdaGRad는 모든 기울기의 제곱을 누적하는 반면, RMSProp는 최신 기울기의 제곱에 더 큰 비중을 둬서 과거의 값들을 서서히 잊혀지게 만드는 효과를 가져옵니다.
	- 이를 이미지로 표현해 두 방법을 비교해보면 아래와 같습니다.
	  
![](https://i.imgur.com/1GP8nZ9.gif)

- 초록색이 RMSProp의 최적화경로이고, 흰핵은 기존 AdaGrad 의 최적화 경로를 나타냅니다. 

1. **감쇠된 기울기 제곱의 합**
- RMSProp에서 $g_t$ ​의 업데이트는 현재 기울기의 제곱에 $(1 - \gamma)$ 을 곱한 값과 이전의 $g_{t−1}$ ​에 $\gamma$ 을 곱한 값을 더하는 방식으로 이루어집니다. 
- 이는 최신 기울기에 더 높은 가중치를 부여함으로써, 오래된 기울기의 영향을 감소시킵니다.
    
2. **감쇠율의 스케일링 효과**
- 감쇠율은 단순히 과거 기울기를 잊어버리게 하는 것뿐만 아니라, 전체 항에 대한 스케일링 효과도 가지고 있습니다. 
- 만약 감쇠율이 0.99로 설정된다면, 기울기의 제곱 합은 AdaGrad의 제곱 합의 루트(1 - 0.99) = 0.1배가 됩니다. 
- 이는 동일한 학습률을 사용할 때 RMSProp의 학습 단계가 AdaGrad에 비해 약 10배 크다는 것을 의미합니다.
    
3. **AdaGrad와 RMSProp의 비교**
- 초기에는 AdaGrad(백색)와 RMSProp(녹색)가 조정된 학습률과 감쇠율로 인해 비슷한 성능을 보입니다. 
- 하지만, AdaGrad는 기울기의 제곱의 누적값이 매우 빠르게 증가하여 결국 거대한 값이 되고, 이로 인해 실질적으로 학습이 정지됩니다.
- 반면에 RMSProp은 감쇠율 덕분에 항상 기울기의 제곱을 관리 가능한 크기로 유지합니다. 
- 이는 RMSProp이 AdaGrad보다 더 빠르게 최적점으로 수렴할 수 있음을 의미합니다.
- 위 이미지에서 보이는 반투명한 벽의 크기가 이를 표현한 것 입니다.
    

> 이러한 감쇠율의 효과로 RMSProp은 학습 과정 중 기울기의 제곱의 누적값을 효율적으로 조절하여, AdaGrad가 겪는 학습률 급감 문제를 피하면서 안정적이고 빠른 수렴을 가능하게 합니다.
> 즉, 변수간의 상대적 학습률 차이는 유지하면서도 $g_t$ 가 무한정 처지지 않도록해 학습을 오래할 수 있게 한 것입니다.

#### RMSProp의 수식 구현
```python
class RMSprop:
    """RMSprop 옵티마이저 클래스입니다."""

    def __init__(self, lr=0.01, decay_rate=0.99):
        # 학습률(lr)과 감쇠율(decay_rate)을 초기화합니다.
        self.lr = lr
        self.decay_rate = decay_rate
        self.h = None
        
    def update(self, params, grads):
        if self.h is None:
            # 처음 업데이트를 수행할 때 h를 초기화합니다. 
            # h는 각 매개변수의 이전 그래디언트 제곱의 이동 평균을 저장합니다.
            self.h = {}
            for key, val in params.items():
                self.h[key] = np.zeros_like(val)
            
        for key in params.keys():
            # 매개변수 별로 h를 업데이트합니다.
            self.h[key] *= self.decay_rate  # h에 decay_rate를 곱해 이동 평균을 계산합니다.
            
            # 현재 그래디언트의 제곱을 h에 더합니다. 이는 그래디언트 제곱의 새로운 이동 평균을 계산하는 단계입니다.
            self.h[key] += (1 - self.decay_rate) * grads[key] * grads[key]
            
            # 매개변수를 업데이트합니다. 여기서는 그래디언트를 제곱근으로 나눠서 학습률을 조정합니다.
            # 이는 각 매개변수의 업데이트 크기를 조정하여 안정적인 학습을 돕습니다.
            params[key] -= self.lr * grads[key] / (np.sqrt(self.h[key]) + 1e-7)
```

1. **초기화 및 매개변수 설정**
    - `lr`: 학습률 (learning rate)로, 매개변수가 얼마나 크게 업데이트될지를 결정합니다.
    - `decay_rate`: 감쇠율로, 과거 그래디언트가 현재 그래디언트에 미치는 영향을 조절합니다.
    - `h`: 각 매개변수에 대한 그래디언트의 제곱 평균을 저장하는 변수입니다. 초기에는 None으로 설정되어 있으며, 첫 번째 업데이트 시에 0으로 초기화됩니다.
      
2. **h의 업데이트**
    - 이전의 `h` 값에 `decay_rate`를 곱합니다. 이는 과거 그래디언트 정보가 지니는 가중치를 줄이는 역할을 합니다.
    - 현재 그래디언트의 제곱(`grads[key] * grads[key]`)을 구하고, 이를 `1 - decay_rate`와 곱하여 `h`에 더합니다. 
    - 이는 현재 그래디언트 정보를 `h`에 반영하는 과정입니다.
      
3. **매개변수의 업데이트**
    - 계산된 `h` 값의 제곱근에 1e-7을 더한 값으로 현재 그래디언트(`grads[key]`)를 나눕니다. 
    - 1e-7은 0으로 나누는 것을 방지하기 위한 작은 값입니다.
    - 이렇게 조정된 그래디언트에 학습률(`lr`)을 곱한 후, 현재 매개변수(`params[key]`)에서 빼줍니다. 이로써 매개변수가 업데이트됩니다.

#### RMSProp의 최적화 수행과정
$$f(x,y) = \frac{1}{20}x^2+y^2$$ 
![](https://i.imgur.com/D0lJr7b.png)


### [Adam](Adam.md) 
- Adam은 모멘텀과 RMSProp의 장점만을 합쳐놓은 최적화 방법입니다. 마치 Ridge 와 Lasso 의 장점만을 합쳐둔 Elasticnet과 같은 방식입니다.
	- 책에선 AdaGrad와 합친것이라 하지만, 실제로는 RMSProp와 합친것 입니다.
- 이론 자체는 다소 복잡하지만 직관적으로는 두 방법을 융합한 듯한 방법이기에 그렇게 표현합니다.
- 두 개의 방법의 장점만을 합친 방식이므로 매개변수 공간을 좀 더 효율적으로 탐색할 수 있으며, 하이퍼파라미터의 '편향 보정' 이 된다는 것이 장점입니다.
- Adam의 수식을 살펴보면 아래와 같습니다.

$m_t = \beta _1m_{t_1} + (1-\beta _1)\nabla f(x_{t-1})$
$g_t = \beta_2 g_{t-1} + (1 - \beta_2)(\nabla f(x_{t-1}))^2$
$\hat{m}_t = \frac{m_t}{1-\beta_1^t}, \hat{g}_t = \frac{g_t}{1-\beta_2^t}$
$x_t = x_{t-1} - \frac{\eta}{\sqrt{\hat{g}_t} + \epsilon} \hat{m}_t$

1. **모멘텀(이동 평균)을 이용한 그래디언트의 누적**
    - 첫 번째 모멘트($m_t$, 이동 평균)는 과거 그래디언트의 모멘텀 $m_{t-1}$과 현재 그래디언트의 가중 평균을 계산합니다.
    - $\beta_1$은 첫 번째 모멘트(이동 평균)에 대한 감쇠율로, 이전 그래디언트의 영향력을 조절합니다.
      
2. **RMSProp(이동 분산)을 이용한 그래디언트 제곱의 누적**
    - 두 번째 모멘트($g_t$, 이동 분산)는 과거 그래디언트 제곱 $g_{t-1}$과 현재 그래디언트 제곱의 가중 평균을 계산합니다.
    - $\beta_2$는 두 번째 모멘트(이동 분산)에 대한 감쇠율로, 이전 그래디언트 제곱의 영향력을 조절합니다.
      
3. **파라미터 업데이트를 위한 변화량의 계산**
    - 첫 번째 모멘트($m_t$, 이동 평균)와 두 번째 모멘트($g_t$, 이동 분산)에 편향 보정을 적용합니다. 이는 알고리즘 초기에 $m_t$와 $g_t$가 낮게 시작되는 경향을 보정하기 위함입니다.
    - 보정된 첫 번째 모멘트는 $\hat{m}_t$, 두 번째 모멘트는 $\hat{g}_t$입니다.
      
4. **파라미터 업데이트 적용**
    - 파라미터 업데이트는 보정된 모멘트를 이용해 계산됩니다.
    - 학습률 $\eta$는 각 스텝에서의 파라미터 업데이트 크기를 결정합니다.
    - $\epsilon$은 나눗셈에서 0으로 나누는 것을 방지하기 위해 추가된 매우 작은 상수입니다.

#### RMSProp의 최적화 수행과정
$$f(x,y) = \frac{1}{20}x^2+y^2$$
![](https://i.imgur.com/nRknX5r.png)

- Adam의 최적화 경로도 모멘텀처럼 바닥을 구르듯 움직이는 것을 확인할 수 있지만 모멘텀보다는 공의 좌우 흔들림이 적습니다.
- 이것은 RMSProp을 적용해 학습의 갱신강도를 조정했기에 가능한 것입니다.

## 어느 갱신방법을 이용할 것인가?
- RMSProp를 포함해 5개의 최적화 방법을 살펴봤습니다.
- 이에 대한 비교를 해보자면 아래와 같습니다.
  
![](https://i.imgur.com/krVTXoF.png)

- 지금까지의 흐름이나 그림으로만 본다면 RMSProp가 가장 나은 방법처럼 보입니다.
- 하지만 이것은 위에서 사용한 $f(x,y) = \frac{1}{20}x^2+y^2$ 라는 함수에 대해서만 한정적으로 그런 것 입니다.
- 즉, 어떤 갱신방법을 사용할 것인가는 풀어야할 문제가 무엇인가에 따라 달라집니다.
- 또한, 같은 방법이라 해도 하이퍼파라미터를 어떻게 설정하는가도 매우 중요한 차이를 발생시킵니다.
- 각자의 장단점이 있는 것 입니다. 다른 데이터셋으로 비교를 해보면 더 좋을 것 같습니다.
#### MNIST 데이터셋으로 본 갱신 방법 비교
- MNIST 데이터셋에 따른 학습 진도 비
![](https://i.imgur.com/mTmdTmx.png)

- 📌 책과 다르게 RMSProp에 대한 그래프를 추가하였습니다.
- 각 층이 100개의 뉴런으로 구성된 5층 신경망에 ReLU를 [활성화 함수(Activate Function)](활성화%20함수(Activate%20Function).md) 로 사용해 측정했습니다.
- 각 방법별로 해석을 해보면 아래와 같습니다.

- **SGD (파란색 선)**: 가장 기본적인 확률적 경사 하강법입니다. 손실이 서서히 감소하며 다른 알고리즘들에 비해 상대적으로 느리게 수렴하는 것을 볼 수 있습니다.
    
- **Momentum (주황색 선)**: 관성의 개념을 도입한 SGD 변형으로, 이전 업데이트가 미치는 영향을 고려합니다. 일반 SGD에 비해 빠르게 수렴하는 것을 볼 수 있으며, 이는 관성이 국소 최소값(local minima)에서 벗어나는 데 도움을 줄 수 있기 때문입니다.
    
- **AdaGrad (녹색 선)**: 학습률을 적응적으로 조정하여 각 매개변수에 대해 개별적인 학습률을 적용합니다. 초기에는 빠른 학습을 보이지만, 나중에는 손실이 거의 감소하지 않는 것을 볼 수 있습니다. 이는 학습률이 너무 빨리 감소하여, 학습이 제대로 진행되지 않을 수 있음을 나타냅니다.
    
- **Adam (빨간색 선)**: 모멘텀과 RMSProp의 아이디어를 결합한 알고리즘으로, 이 그래프에서는 가장 빠르고 안정적으로 손실을 줄이는 것으로 보입니다. 이는 여러 다양한 문제에 대해 좋은 성능을 보이는 경향이 있음을 나타냅니다.
    
- **RMSProp (보라색 선)**: 그래디언트의 제곱 평균을 사용하여 학습률을 조정합니다. Adam과 마찬가지로 초기 손실 감소가 빠르며, AdaGrad의 문제점을 개선한 알고리즘으로 알려져 있습니다.
    

> 종합적으로, Adam이 이 경우에 가장 좋은 성능을 보이고 있으며, AdaGrad는 학습률이 너무 빨리 줄어들어 후반부에 성능이 개선되지 않는 문제를 보여주고 있습니다. 
> SGD와 Momentum은 더 천천히, 그러나 지속적으로 손실을 줄여나가고 있습니다. 이 그래프를 통해, MNIST 데이터셋에 대한 학습에서 Adam과 RMSProp이 특히 효과적인 최적화 방법임을 알 수 있습니다.


*✔️다만 하이퍼파라미터인 학습률의 신경망의 구조(층의 깊이 등) 에 따라 이 결과는 얼마든지 달라질 수 있음을 유의해야 합니다.*

## 최적의 결과를 도출하기 위한 방법들
### 가중치의 초기값
- 신경망의 학습에서 가장 중요한 것은 가중치의 초기값 입니다.
- 이 초기값을 무엇으로 설정하느냐에 따라 신경망의 학습 성능이 정해진다 해도 과언이 아닙니다.
- 그렇다면 이를 위한 권장 초기값은 어떻게 설정해야 할까요?

#### 초기값을 0으로 하는 경우
- 신경망 학습에서 [과대적합(Overfitting)](과대적합(Overfitting).md) 방지를 위해 범용 성능을 높이는 [[가중치 감소(weight decay)]] 를 흔히 사용합니다.

![가중치 감소(weight decay)](가중치%20감소(weight%20decay).md)

- 쉽게 말해 가중치의 매개변수값이 작아지도록 학습시키는 방법으로, 가중치 값을 작게해서 오버피팅을 방지 합니다.
- 이러한 가중치를 작게 만드는 가장 쉬운 방법은 *초기값을 최대한 작게 시작하는 것* 입니다.
- 그렇다면 초기값을 0으로 설정한다면 가중치를 가장 작게 만드는 것은 어떨까요?
- 가중치를 0으로 초기화하는 것은 좋지 않은 방법입니다. 
	- 가중치를 모두 0으로 초기화하면, 오차 역전파법에서 모든 가중치의 값이 똑같이 갱신되기 때문입니다. 
	- 이러한 상황을 가중치의 대칭적인 구조로 불리우며, 이를 통해 모든 뉴런이 같은 값을 출력하게 되어, 뉴런을 여러 개 둔 의미가 없어집니다.
	- 따라서 *가중치 초기값은 작은 무작위 값을 선택하여 대칭성을 깨뜨리는 것이 일반적*입니다. 
	- 이렇게 하면 각 뉴런이 다른 값을 가지게 되어, 학습 과정에서 각각 다른 특성을 학습할 수 있습니다.

### 은닉층의 활성화값 분포
- 은닉층의 활성화값(활성화 함수의 출력 데이터) 의 분포를 살펴보면 최적화를 위한 하이퍼파라미터 튜닝을 위한 다양한 정보를 얻을 수 있습니다.
- 은닉층의 활성화 값으로 파악할 수 있는 정보는 아래와 같습니다.
	- 가중치의 초기값 설정은 적절한지
	- 학습이 잘 진행되고 있는지
- 이를 위해 주로 3가지 실험을 합니다.

1. **가중치 초기값 설정 확인**
- 가중치 초기값에 따라 활성화값들이 어떻게 변화하는지를 관찰함으로써, 초기값 설정이 적절한지 판단할 수 있습니다. 
- 예를 들어, 가중치 초기값이 너무 작으면 활성화값들이 0에 치우쳐져 그래디언트 소실 문제가 발생할 수 있습니다. 
- 반대로 초기값이 너무 크면 활성화값들이 고르게 분포하지 않고 일부에 치우칠 수 있습니다.
    
2. **활성화 함수 선택 확인**
- 활성화 함수에 따라 활성화값의 분포가 달라집니다. 
- 예를 들어, 시그모이드 함수를 사용하면 활성화값이 0과 1에 치우치는 경향이 있으며, 이는 그래디언트 소실 문제를 야기할 수 있습니다. 
- 반면, ReLU 함수를 사용하면 이 문제를 완화할 수 있습니다.
    
3. **학습 진행 상황 확인**
- 학습이 진행되면서 활성화값 분포가 어떻게 변화하는지를 관찰함으로써, 학습이 잘 진행되고 있는지 확인할 수 있습니다. 
- 만약 활성화값 분포가 지나치게 일정한 패턴을 보인다면, 학습이 제대로 이루어지지 않고 있을 수 있는 신호입니다.

##### 가중치 초기값설정에 따른 활성화 값의 변화
- 책에서 가중치 초기값에 따른 변화를 살펴보기 위해 시그모이드 함수를 기반으로 하는 5층신경망을 활용합니다.

```python
import numpy as np
import matplotlib.pyplot as plt

# 시그모이드 활성화 함수 정의
def sigmoid(x):
    return 1 / (1 + np.exp(-x))

# ReLU 활성화 함수 정의
def ReLU(x):
    return np.maximum(0, x)

# 하이퍼볼릭 탄젠트 활성화 함수 정의
def tanh(x):
    return np.tanh(x)
    
# 입력 데이터 생성: 1000개의 데이터 포인트와 각각 100개의 특성을 가짐
input_data = np.random.randn(1000, 100)

# 각 은닉층의 노드(뉴런) 수
node_num = 100

# 은닉층 개수
hidden_layer_size = 5

# 활성화 결과를 저장할 딕셔너리
activations = {}

# 초기 입력 데이터
x = input_data

# 은닉층을 순회하면서 활성화 함수를 적용하고 결과를 저장
for i in range(hidden_layer_size):
    if i != 0:
        x = activations[i-1]

    # 가중치 초기화 - 여기에서는 표준편차 1로 초기화
    w = np.random.randn(node_num, node_num) * 1
    # 다른 초기화 방법들도 실험해보세요.
    # w = np.random.randn(node_num, node_num) * 0.01
    # w = np.random.randn(node_num, node_num) * np.sqrt(1.0 / node_num)
    # w = np.random.randn(node_num, node_num) * np.sqrt(2.0 / node_num)

    # 활성화 함수 적용
    a = np.dot(x, w)

    # 활성화 함수도 변경해서 실험할 수 있습니다.
    z = sigmoid(a)
    # z = ReLU(a)
    # z = tanh(a)

    # 활성화 결과를 저장
    activations[i] = z

# 팔레트 크기 조절 
plt.figure(figsize=(15, 5)) # 가로 15, 세로 5의 크기로 조정

# 히스토그램 그리기
for i, a in activations.items():
    plt.subplot(1, len(activations), i+1)
    plt.title(str(i+1) + "-layer")
    if i != 0: plt.yticks([], [])
    # 다음 두 줄은 히스토그램의 범위 등을 조정하는 부분으로 필요에 따라 주석을 해제하고 사용하세요.
    # plt.xlim(0.1, 1)
    # plt.ylim(0, 7000)
    plt.hist(a.flatten(), 30, range=(0,1))

# 그래프를 화면에 표시
plt.show()
```

![](https://i.imgur.com/RygoqJH.png)

- 각 층의 활성화 함수들이 0~1 양 극단에 치우쳐 분포 되어 있습니다.
- 시그모이드 함수는 출력이 0 또는 1에 가까워지면 미분값이 0에 수렴합니다.
- 이러한 데이터 분포에서 역전파를 하게 되면  기울기 값이 점점 작아지다가 사라지는 [[기울기 소실(Gradient Vanishing)]] 문제를 발생시킵니다.
	- 기울기 소실은 역전파 과정에서 학습이 진행될수록 입력층에 가까운 층들의 가중치가 잘 갱신되지 않는 문제를 말합니다. 
	- 위 그래프를 보면 시그모이드 함수의 미분값이 최대 0.25이기 때문에, 역전파 과정에서는 이 미분값이 계속 곱해지게 됩니다. 
	- 그래서 네트워크가 깊어질수록 이 값이 계속 작아져 결국에는 가중치가 거의 갱신되지 않게 되는 현상이 발생하게 됩니다.

> 결과적으로, 대부분의 데이터가 0과 1에 수렴하게 되면, 활성화값의 분포가 치우치게 되어 표현력을 제한하는 문제와 그래디언트 소실 문제로 인해 학습이 잘 이루어지지 않을 수 있습니다. 
> 이러한 문제를 해결하기 위해 ReLU와 같은 활성화 함수를 사용하는 것이 일반적입니다. 
> ReLU 함수는 입력이 0 이상일 때는 미분값이 1이므로, 그래디언트 소실 문제를 완화할 수 있습니다.

- 그렇다면 가중치의 표준편차에 변화를 준다면 결과가 어떻게 달라질까요?
- 선형데이터에 대해 가장 적합한 시그모이드 함수를 활성화 함수로 해서 가중치의 표준편차가 고르게 퍼지도록 하는 것을 목적으로 조정해 보겠습니다.
- 여기에는 가장 대표적 초기값인 Xavier 초기값($w2$) 가 사용됩니다. 이를 중심으로 살펴보면 결과를 이해하는데 도움이 될 것입니다.

> 📌 Xavier 초기값
![](https://i.imgur.com/PU2mHaL.png)

- Xavier 초기값 개발의 목적은 각 Layer의 활성화 값들을 광범위하게 분포시키기 위한 가중치의 적절한 분포를 찾는 것이었습니다.
- 그렇게 해서 밝혀진 것이 앞계층의 노드가 $n$ 개라면 표준편차가 $\frac {1}{\sqrt n}$ 인 분포를 사용하면 된다는 것 이었습니다.
- Xavier 초기값을 사용하면 앞 층에 노드가 많을 수록 대상 노드의 초기값으로 설정하는 가중치가 좁게 퍼지게 됩니다.

![](https://i.imgur.com/5LNKtWX.png)

- 위 그래프는 가중치의 표준편차를 1에서 각각 0.01, Xavier 초기값($\frac {1}{\sqrt {1.0}}$) , He 초기값($\frac {1}{\sqrt {2.0}}$) 으로 변경한 결과들 입니다.

1. **가중치 초기화 방법에 따른 영향**
    - `w` (표준편차 1): 너무 큰 가중치는 활성화 함수의 출력을 극단적인 값으로 몰아가게 하며, 이는 그래디언트 기반 학습에서 문제를 일으킬 수 있습니다. 결과적으로 *뉴런들이 거의 동일하게 활성화되거나, 거의 활성화되지 않는 현상*이 발생할 수 있습니다.
    - `w1` (표준편차 0.01): *작은 가중치는 뉴런의 출력을 제한하여 신경망의 표현력을 저하*시킵니다. 뉴런들이 유사한 값을 출력하게 되어, *다양한 특성을 학습하는데 제한*을 받게 됩니다.
    - `w2`와 `w3` (Xavier 초기화, He 초기화): 이 방법들은 뉴런의 입력과 출력의 분산을 일정하게 유지하려고 시도합니다. 이는 각 레이어를 통과하면서 활성화 값들이 0과 1 사이에 적절히 분포되도록 하여 *기울기 소실 문제를 완화시키는데 도움이 됩니다.*
      
2. **기울기 소실 문제**
    - 큰 가중치 (`w`)는 활성화 함수를 포화시켜 *기울기가 매우 작아질 수 있어 역전파 시 기울기가 제대로 전파되지 않는 기울기 소실 문제*를 발생시킬 수 있습니다.
    *- 작은 가중치* (`w1`)는 활성화 함수의 *출력이 매우 제한적*이 되어 *기울기가 소실*될 수 있습니다. 이는 학습이 느려지거나 제대로 진행되지 않을 수 있음을 의미합니다.
    - `w2`와 `w3` 방식은 기울기 소실 문제를 줄이는데 도움을 줍니다. 이들은 각 레이어의 출력을 적절하게 분산시켜 역전파 시 기울기가 적절히 유지되도록 합니다.
      
3. **가중치 초기화의 한계**
    - 가중치 초기화만으로는 모든 문제를 해결할 수 없습니다. 예를 들어, *네트워크가 깊어지면 기울기 소실 또는 폭발 문제가 여전히 발생*할 수 있습니다.
    - 또한, 초*기화 방법은 신경망의 구조나 학습률 같은 다른 하이퍼파라미터와 상호작용*하며, 이들 모두가 *최종 학습 성능에 영향*을 미칩니다.
    - 따라서 *가중치 초기화는 신경망 학습의 중요한 부분이지만, 최적의 학습 결과를 얻기 위해서는 다른 요소들도 함께 고려해야 합니다.*

#### ReLU를 사용할 때의 가중치 초기값(He 초기값)
- 위 실험에서 상대적으로 좋은 성능을 보였던 것은 $w2, w3$ 로 이 가중치들은 각각 Xavier와 He 초기값을 의미했습니다.
- Xavier의 경우 활성화 함수가 선형임을 가정했을때 사용하기 적합한 초기값입니다.
- 반면에 He 초기값의 경우 활성화 함수가 비선형인 경우(ex. ReLU) 에 더 특화된 초기값입니다.
- 위의 그래프에서 살펴본 He초기값은 시그모이드 함수에 적용된 결과였습니다. 이번에는 활성화 함수를 ReLU로 적용했을 때의 결과를 살펴보겠습니다.
	- He의 값은 앞계층의 노드가 $n$ 개 일때, 표준편차가 $\sqrt \frac{2}{n}$ 인 정규분포를 사용합니다. ReLU는 음의 영역은 모두 0을 출력하기 때문에 2배의 계수가 필요하기 때문입니다.

![](https://i.imgur.com/XDoEAfu.png)

- 비교를 위해 위쪽 2줄은 시그모이드를 활성화 함수로 했을때의 각 Layer별 활성화 값의 변화를 그렸고 아래쪽 2줄은 활성화 함수를 ReLU로 했을 때의 결과를 그렸습니다.
  
- 1. **시그모이드 - Xavier 초기값**
    - 각 층의 활성화 값들이 비교적 균일하게 분포되어 있습니다. 
    - 이는 *Xavier 초기값이 시그모이드 활성화 함수와 잘 맞는 것*을 보여줍니다. 
    - 이 초기값은 입력과 출력의 분산을 조절하여 깊은 네트워크에서도 활성화 값들이 균일하게 분포되도록 돕습니다.
      
1. **시그모이드 - He 초기값**
    - He 초기값은 ReLU 활성화 함수를 위해 설계되었기 때문에, 시그모이드 함수와 사용했을 때의 분포가 Xavier 초기값과 비교해 약간 더 치우친 경향을 보입니다. 
    - 그러나 여전히 활성화 값들은 0과 1 사이에 적절히 분포되어 있습니다.
      
2. **ReLU - Xavier 초기값**
    - Xavier 초기값은 시그모이드 함수를 위해 설계되었지만, ReLU 함수와 함께 사용했을 때도 활성화 값들이 어느 정도 균일하게 분포하는 것을 볼 수 있습니다. 
    - 그러나 ReLU와 함께 사용할 때는 값들이 0에 치우친 분포를 보이는 것이 일반적입니다.
      
3. **ReLU - He 초기값**
    - He 초기값은 ReLU 함수와 잘 어울리며, 따라서 *활성화 값들이 0 이상에서 좀 더 균일하게 분포*되어 있는 것을 확인할 수 있습니다. 
    - ReLU 함수는 음수 입력에 대해 0을 출력하기 때문에, He 초기값과의 조합이 활성화 값들을 적절히 분포시키는데 도움을 줍니다.

💡 각 활성화 함수별로 더 적절한 초기값은 무엇일까?

1. **시그모이드 활성화 함수**: 
- 시그모이드 함수에는 **Xavier 초기값**이 가장 적절해 보입니다. 
- 그 이유는 Xavier 초기값이 네트워크의 각 층에서 활성화 값들이 균일하게 분포되도록 설계되었기 때문입니다. 
- 시그모이드 함수는 출력 값이 0과 1 사이에 있으며, Xavier 초기값은 이러한 활성화 함수의 특성에 맞추어 입력과 출력의 분산을 조절합니다.
    
2. **ReLU 활성화 함수**
- ReLU 함수에는 **He 초기값**이 가장 적절합니다. 
- ReLU는 음수 값을 0으로 만들고, 양수 값에 대해서는 선형적으로 반응합니다. 
- He 초기값은 이러한 ReLU의 특성을 고려하여, 은닉층의 뉴런이 적절히 활성화될 수 있도록 분산을 더 크게 설정합니다.

#### MNIST 데이터를 활용한 가중치 초기값 비교
- 여기서는 MNIST 데이터셋을 사용하며, 층별 뉴런수가 100개인 5층 신경망을 구축했고 활성화 함수로 ReLU를 사용했습니다.

![](https://i.imgur.com/D8hAgJd.png)

- std 값이 0.01 일때는 학습이 전혀 이뤄지지 않습니다. 순전파에서 너무 작은 값(0근처에 밀집된 데이터) 가 흐르기 때문입니다.
	- 이는 역전파에도 영향을 미쳐 기울기가 작아지고 거의 갱신이 도지 않는 문제가 생기는 것입니다.ㅏ
- Xavier 초기값이나 He초기값의 경우 학습이 적절하게 이뤄지고 있습니다.
- 다만 학습진도는 He 초기값이 더 빠릅니다. 
- 이와 같이 학습의 초기값을 무엇으로 설정하느냐에 따라 모델의 성능에 영향을 미칠 수 있음을 확인했습니다.

## [[배치 정규화(Batch Normalization)]] 
- 위의 실험에서 가중치의 초기값을 적절하게 설정하면 모델 성능 향상에 도움이 됨을 확인했습니다.
- "만약 각 층마다 이 활성화값을 적당히 퍼트리도록 강제한다면 학습이 잘 될까?" 라는 아이디어에서 도출된 방법이 배치 정규화 입니다.
- 배치 정규화는 아래 3가지 이유로 최근에 주로 사용됩니다.
	1) 학습을 빨리 진행할 수 있다. (학습 속도 개선)
	2) 초기값에 크게 의존하지 않는다. 
	3) 오버피팅을 억제한다. (드롭아웃의 필요성 감소

- 이러한 배치 정규화의 기본 아이디어는 각 층에서 활성화 값이 적절하게 분포하도록 하는 것으로 이를 위해 '[[배치 정규화 계층(Batch Norm)]]' 신경망에 삽입 합니다.

![배치 정규화 계층(Batch Norm)](배치%20정규화%20계층(Batch%20Norm).md)

- 배치 정규화 계층을 신경망에 삽입하는 경우 아래와 같은 형태가 됩니다.

![](https://i.imgur.com/GSrKG0B.jpg)

- 수식에 대해 복잡한 설명이 있지만, 간략히 말하자면 데이터 분포가 평균이 1, 분산이 1이 되도록 미니 배치 단위로 정규화를 한 것입니다.
- 이러한 배치 처리를 활성화 함수의 앞 또는 뒤에 추가해서 데이터 분포가 덜 치우치도록 할 수 있습니다.

🤔 배치 정규화 계층을 활성화 함수 앞에 적용할때와 뒤에 적용할때의 차이
![🤔 배치 정규화 계층을 활성화 함수 앞에 적용할때와 뒤에 적용할때의 차이](🤔%20배치%20정규화%20계층을%20활성화%20함수%20앞에%20적용할때와%20뒤에%20적용할때의%20차이.md)

#### 배치 정규화의 효과
- 이전과 같이 MNIST 데이터셋을 이용해서 배치 정규화 계층을 사용할때의 학습진도를 그래프로 시각화 하면 아래와 같습니다.

![](https://i.imgur.com/hszKtZK.png)

- 위에서 정리한 바와 같이 배치정규화가 학습을 더 빠르게 하도록 하고 있습니다.
- 다음으로는 초기값 분포를 다양하게 변화했을때의 결과를 비교해 보겠습니다.

- 거의 모든 경우에서 배치정규화를 했을 때의 학습 진도가 빠른 것으로 보입니다.
- 배치 정규화를 이용하지 않은 경우에도 초기값을 잘 분포되지 않으면 학습이 진행되지 않는 모습도 확인이 됩니다.

![](https://i.imgur.com/V4wrHph.png)


> 위 실험을 통해 배치 정규화를 통해 학습속도를 향상시킬 수 있지만, 그 결과가 가중치의 초기값에 크게 의존하지 않음을 확인할 수 있었습니다.


## 바른학습을 위해 고려해야 할 것
- 일반적으로 머신러닝/딥러닝에서 [과대적합(Overfitting)](과대적합(Overfitting).md) 이 문제가 되는 경우가 많습니다.
- 하지만 머신러닝/딥러닝은 범용성능이 높은 모델을 만드는 것을 추추하므로 학습하지 않은 데이터를 입력받아도 올바르게 식별할 수 있어야 합니다.
- 이를 위해 필수적인 것이 과적합을 억제하는 기술입니다.

### 과적합(오버피팅)
- 오버피팅이 일어나는 경우는 크게 2가지 입니다.
	- 매개변수가 많고 표현력이 많은 모델인 경우
	- 훈련 데이터가 적은 경우
- 이러한 경우를 상정해서 억지로 오버피팅을 일으켜 보겠습니다.

![](https://i.imgur.com/wK3cTLT.png)


- 훈련데이터를 사용해 측정한 정확도는 100 epoch를 지날때부터 거의 100% 입니다.
- 반면에, 훈련데이터에 대해서는 큰 차이가 있습니다. 정확도가 크게 벌어지는 이유는 모델이 학습데이터에 대해서 오버피팅 되었기 때문입니다.
- 이러한 오버피팅 억제를 위한 방법은 여러가지가 있습니다. 우선은 가중치를 감소시켜 오버피팅을 억제해 보겠습니다.

#### 가중치 감소를 통한 오버피팅 억제
- 이는 [가중치 감소(weight decay)](가중치%20감소(weight%20decay).md)  를 사용 하는 방법을 말하며, 학습 과정에서 큰 가중치에 대해 그에 상응하는 패널티를 줘서 오버피팅을 억제하는 것이 핵심입니다.
	- 이는 기본적으로 오버피팅이 가중치 매개변수값이 커서 발생하는 경우가 많다는 점에서 착안한 것입니다.ㅏ 

- 신경망 학습의 목적은 결국 손실 함수값을 줄이는 것입니다. 이를 위해 가중치의 제곱 노름([[L2 노름]])을 손실함수에 더해 가중치가 커지는 것을 억제시킬 수 있습니다.

![L2 노름](L2%20노름.md)

- 실험으로 $\lambda = 0.1$  을 적용해 가중치 감소를 시도해 보겠습니다.

![](https://i.imgur.com/L5ZY3SN.png)


- 훈련데이터와 테스트 데이터간의 정확도에는 차이가 여전히 존재하지만, 이전에 비해 확연히 줄어든 것을 확인할 수 있습니다.
- 즉, 오버피팅이 억제가 되었다고 볼 수 있습니다.
- 또한, 훈련데이터의 정확도가 100%가 아니라 감소한 것은 오버피팅된 학습 모델의 일반화 성능이 향상되었음을 의미합니다.
	- 즉, 훈련모델에 대한 오버피팅이 어느정도 개선되었음을 의미합니다.

### [[드롭아웃(Dropout)]]
![드롭아웃(Dropout)](드롭아웃(Dropout).md)

- 이러한 드롭아웃을 적용한 결과를 시각화 해보면 아래와 같습니다.

![](https://i.imgur.com/OsZeLHr.png)

- 드롭아웃을 통해 훈련데이터와 테스트 데이터에 대한 정확도 차이가 확연하게 줄어든 것을 볼 수 있습니다.
- 추가로 오버피팅 되었던 훈련데이터의 일반화 성능도 향상되어 100%에 수렴하지 않고 있습니다.
- 이처럼 드롭아웃을 하면 모델이 가진 데이터에 대한 표현력을 증가시키면서도 오버피팅을 억제할 수 있습니다.

✔️ 표현력을 높인다 : 모델이 데이터의 다양한 특징을 보다 잘 표현할 수 있다.

💡 드롭아웃은 일종의 앙상블
- 드롭아웃이 학습 과정에서 무작위로 뉴런을 비활성화함으로써, 매번 다른 구조의 모델을 학습시키는 것이 앙상블 기법에서 여러 다른 모델을 학습시키는 것과 비슷하다는 의미입니다. 
- 앙상블 기법은 여러 모델의 예측을 종합하여 오차를 줄이는데, 드롭아웃은 학습 과정에서 생성되는 매번 다른 네트워크 구조들이 마치 각기 다른 모델들처럼 작용하므로, 이를 '앙상블과 비슷하다'고 할 수 있습니다.

## 적절한 하이퍼파라미터 찾기
- 신경망에서 사용되는 하이퍼파라미터는 다양합니다.
- 각 층의 뉴런수, 배치 크기, 매개변수의 갱시 학습률, 가중치 감소 등이 대표적입니다.
- 그러나 앞선 여러 실험에서 알 수 있듯, 적절한 하이퍼파라미터값을 설정하지 않으면 모델의 성능이 크게 저하될 수도 있습니다.
	- 또는, 모델 성능의 크게 개선되지 않을 수 도 있습니다.
- 딥러닝의 특징중 하나는 매우 오랜 학습시간이 소요된다는 것입니다. 
	- 따라서 적절한 하이퍼파라미터를 찾지 못하면 오랜시간 학습을 시키고도 좋지 못한 결과를 얻는 경우가 다반사 입니다.
- 이를 방지하고 최적의 하이퍼파라미터를 찾기 위한 여러 방법들이 있습니다.

### 검증데이터(Validation set) 활용
- 모델 학습시 다양한 하이퍼파라미터를 설정하게 되는데, 그 결과가 적절한지를 테스트하는 것이 필요합니다.
- 이전까지의 설명에서는 테스트 데이터로 그 결과를 검증했지만, 사실 이는 잘못된 방법입니다.
- 하이퍼파라미터의 조정은 학습데이터에 하이퍼파라미터를 적용해 학습시키고 그 결과를 확인해 하이퍼파라미터를 조정해 재학습 시키는 과정의 반복입니다.
- 그런데, 테스트 데이터를 사용해 하이퍼파라미터의 값을 조정하면, 하이퍼파라미터값도 테스트데이터에 오버피팅이 됩니다.
- 즉, 결과가 좋은 하이퍼파라미터를 테스트데이터로 확인하면 하이퍼파라미터의 값은 '테스트 데이터의 값이 잘 나오게 하기 위한 하이퍼파라미터' 가 되버립니다.
	- 이는 모델의 범용성을 저하시키는 결과를 도출합니다.

### 하이퍼파라미터 최적화
- 하이퍼파라미터 최적화의 핵심은 하이퍼파라미터의 최적값이 존재하는 범위를 '조금씩' 줄여나간다는 것 입니다.
- 이 '범위를 조금씩 줄이기' 위해 대략적인 하이퍼파라미터의 범위를 설정한 후, 임의로 값을 골라내서(샘플링) 그 값으로 정확도를 평가하는 것입니다.
- 머신러닝의 그리드 서치(Grid Search) 처럼 규칙적으로 탐색하도록 하면 좋겠지만, 일반적으로 딥러닝에서는 그러한 방법이 더 나쁜 결과를 초래하곤 합니다.
- 따라서 하이퍼파라미터의 범위는 '대략적' 으로 지정하는게 더 효과적입니다.

🤔 왜 딥러닝에서는 하이퍼파라미터 범위를 대략적으로 지정할까
![🤔 왜 딥러닝에서는 하이퍼파라미터 범위를 대략적으로 지정할까](🤔%20왜%20딥러닝에서는%20하이퍼파라미터%20범위를%20대략적으로%20지정할까.md)

- 가장 보편적인 하이퍼파라미터 최적화를 위한 탐색방법은 아래와 같습니다.
	- 0단계 : 하이퍼파라미터 값의 범위 설정 (로그스케일 활용)
	- 1단계 : 설정된 범위에서 하이퍼파라미터값 무작위 추출(샘플링)
	- 2단계 : 샘플링한 하이퍼파라미터값을 사용해 학습한뒤, 검증데이터로 정확도 평가(epoch은 작게 설정)
	- 3단계 : 1~2단계를 특정횟수(ex. 100회) 반복하고, 그 정확도를 확인해 하이퍼파라미터의 범위를 좁힌다.

🤔 딥러닝의 하이퍼파라미터 최적화에서 epoch을 작게 설정하는 이유
![🤔 딥러닝의 하이퍼파라미터 최적화에서 epoch을 작게 설정하는 이유](🤔%20딥러닝의%20하이퍼파라미터%20최적화에서%20epoch을%20작게%20설정하는%20이유.md)

💡 [[베이지안 최적화(Bayesian Optimization)]]
![베이지안 최적화(Bayesian Optimization)](베이지안%20최적화(Bayesian%20Optimization).md)

### 하이퍼파라미터 최적화 구현하기
- 하이퍼파라미터의 값을 로그스케일로 0.001~1.000 ($10^{-3} ~ 10^3$) 으로 설정하고 샘플링 합니다.
- 그리고 이를 시각화한 결과는 아래와 같습니다.

![](https://i.imgur.com/rg9IrbI.png)

- Best-5 정도까지는 학습이 순조롭게 진행되고 있습니다.
- 이 부분의 하이퍼파라미터값(학습률, 가중치 감소 계수) 를 살펴보면 다음과 같습니다.
```
val acc:0.06 | lr:0.000817988860720815, weight decay:3.963222077287312e-06
val acc:0.13 | lr:3.214369795642347e-05, weight decay:1.0295497062998586e-07
val acc:0.08 | lr:3.3570210104210064e-05, weight decay:6.179346259118175e-08
val acc:0.1 | lr:6.75892218076113e-05, weight decay:1.62115017444389e-08
val acc:0.14 | lr:3.0005151940056062e-05, weight decay:4.6903132188629095e-07
```
- 주어진 결과를 보면, 하이퍼파라미터 최적화 과정에서 다양한 학습률(`lr`)과 가중치 감소 계수(`weight_decay`)의 조합을 시도한 것을 알 수 있습니다. 
- 여기서 학습률은 대략 $10^{−6}$ 부터 $10^{−4}$ 사이, 가중치 감소 계수는 대략 $10^{−8}$부터 $10^{−6}$ 사이의 범위에서 변화하고 있습니다.

**관찰 결과**:
- 가장 높은 검증 정확도(`val acc`)는 0.14로, 학습률이 약 3×10−53×10−5이고 가중치 감소 계수가 약 4.69×10−74.69×10−7일 때 나왔습니다.
- 검증 정확도가 상대적으로 낮은 경우들은 학습률이 더 낮거나 더 높을 때 발생합니다. 
	- 예를 들어, 정확도가 0.06인 경우 학습률이 8.17×10−48.17×10−4로 상대적으로 높습니다.

**다음에 해야 할 액션:**
- 현재 결과에서 가장 좋은 성능을 보인 범위 주변에서 더 세밀하게 하이퍼파라미터를 조정해보는 것이 좋습니다. 
- 즉, 학습률을 2×10−52×10−5부터 4×10−54×10−5 사이, 가중치 감소를 10−710−7부터 10−610−6 사이에서 탐색해볼 수 있습니다.
- 또한, 더 넓은 범위에서 추가적인 무작위 탐색을 수행하거나, 현재 탐색된 범위를 바탕으로 보다 세밀한 그리드 탐색(grid search)을 수행할 수도 있습니다.
- 이러한 탐색을 통해 얻은 새로운 조합으로 다시 학습을 실행하여, 성능 향상이 있는지 확인합니다. 
- 만약 성능 향상이 관찰되면, 해당 하이퍼파라미터를 사용하여 더 큰 데이터셋에 대한 학습을 시도해볼 수 있습니다.
- 마지막으로, 이러한 실험 과정에서 학습 곡선(learning curve)을 주의 깊게 관찰하여, 과대적합(overfitting)이나 과소적합(underfitting)의 징후를 찾고 그에 맞게 하이퍼파라미터를 조정하는 것이 중요합니다.

🤔 딥러닝에서 그리드서치를 해도 되는 경우?
![🤔 딥러닝에서 그리드서치를 해도 되는 경우](🤔%20딥러닝에서%20그리드서치를%20해도%20되는%20경우.md)


- 참고로, 하이퍼파라미터 최적화와 위 시각화 그래프를 그리는 코드는 아래와 같습니다.
```python
import sys, os
sys.path.append(os.pardir)  # 현재 스크립트에서 부모 디렉터리의 모듈을 가져올 수 있게 경로 추가
import numpy as np
import matplotlib.pyplot as plt
from dataset.mnist import load_mnist  # MNIST 데이터셋 로드 모듈
from common.multi_layer_net import MultiLayerNet  # 다층 신경망 모델
from common.util import shuffle_dataset  # 데이터셋 셔플 모듈
from common.trainer import Trainer  # 신경망 훈련을 위한 트레이너 모듈

# MNIST 데이터셋을 불러오고, 입력 데이터를 0에서 1 사이의 값으로 정규화
(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)

# 훈련 데이터를 500개로 줄여서 실험 시간을 단축
x_train = x_train[:500]
t_train = t_train[:500]

# 훈련 데이터의 20%를 검증 데이터로 분할하기 위한 준비
validation_rate = 0.20
validation_num = int(x_train.shape[0] * validation_rate)
x_train, t_train = shuffle_dataset(x_train, t_train)  # 데이터셋을 무작위로 섞음
x_val = x_train[:validation_num]  # 검증 데이터 분할
t_val = t_train[:validation_num]
x_train = x_train[validation_num:]  # 나머지는 훈련 데이터로 사용
t_train = t_train[validation_num:]


def __train(lr, weight_decay, epocs=50):
    # 다층 신경망을 생성하고, L2 정규화(가중치 감소)를 적용
    network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],
                            output_size=10, weight_decay_lambda=weight_decay)
    # 트레이너 객체를 생성하여 신경망을 훈련. SGD를 사용하고, 주어진 학습률과 에폭 수를 적용
    trainer = Trainer(network, x_train, t_train, x_val, t_val,
                      epochs=epocs, mini_batch_size=100,
                      optimizer='sgd', optimizer_param={'lr': lr}, verbose=False)
    trainer.train()

    return trainer.test_acc_list, trainer.train_acc_list

# 하이퍼파라미터를 무작위로 탐색하는 과정 시작
optimization_trial = 100
results_val = {}
results_train = {}
for _ in range(optimization_trial):
    # 가중치 감소와 학습률에 대한 하이퍼파라미터의 범위를 설정
    weight_decay = 10 ** np.random.uniform(-8, -4)
    lr = 10 ** np.random.uniform(-6, -2)

    # 훈련을 진행하고, 검증 데이터와 훈련 데이터에 대한 정확도를 기록
    val_acc_list, train_acc_list = __train(lr, weight_decay)
    print("val acc:" + str(val_acc_list[-1]) + " | lr:" + str(lr) + ", weight decay:" + str(weight_decay))
    key = "lr:" + str(lr) + ", weight decay:" + str(weight_decay)
    results_val[key] = val_acc_list
    results_train[key] = train_acc_list

# 최적화 결과를 그래프로 시각화
print("=========== Hyper-Parameter Optimization Result ===========")
# 전체 그래프의 크기를 설정
plt.figure(figsize=(20, 20))

# 가장 좋은 결과를 보인 상위 20개의 하이퍼파라미터 조합을 그래프로 그림
graph_draw_num = 20
col_num = 5
row_num = int(np.ceil(graph_draw_num / col_num))
i = 0

# 검증 정확도가 높은 순으로 정렬하여 그래프로 표현
for key, val_acc_list in sorted(results_val.items(), key=lambda x:x[1][-1], reverse=True):
    print("Best-" + str(i+1) + "(val acc:" + str(val_acc_list[-1]) + ") | " + key)

    plt.subplot(row_num, col_num, i+1)
    plt.title("Best-" + str(i+1))
    plt.ylim(0.0, 1.0)
    if i % col_num: plt.yticks([])  # 첫 번째 열을 제외한 나머지 열의 y축 눈금 레이블을 숨김
    plt.xticks([])  # x축 눈금 레이블을 숨김
    x = np.arange(len(val_acc_list))
    plt.plot(x, val_acc_list)  # 검증 데이터 정확도를 그래프에 표현
    plt.plot(x, results_train[key], "--")  # 훈련 데이터 정확도를 그래프에 표현
    i += 1

    if i >= graph_draw_num:
        break

plt.show()
```

